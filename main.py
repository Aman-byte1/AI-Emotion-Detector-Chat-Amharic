import streamlit as st
import cv2
import numpy as np
# from PIL import Image
# import pickle
import os
import time
import io

import google.generativeai as genai
from inference_sdk import InferenceHTTPClient

# --- PAGE CONFIG MUST BE THE FIRST STREAMLIT COMMAND ---
st.set_page_config(page_title="á‹¨áˆµáˆœá‰µ áˆ˜áˆ˜áˆ­áˆ˜áˆªá‹« áŠ¥áŠ“ AI Chat", layout="wide")

# --- Constants ---
HAAR_CASCADE_PATH = cv2.data.haarcascades + 'haarcascade_frontalface_default.xml'
AMHARIC_FONT_STYLE = "font-family: 'Noto Sans Ethiopic', sans-serif;"

# --- Load Haar Cascade ---
haar_cascade_loaded = False
if not os.path.exists(HAAR_CASCADE_PATH):
    FACE_CASCADE = None
    # print("DEBUG: Haar Cascade file not found.")
else:
    FACE_CASCADE = cv2.CascadeClassifier(HAAR_CASCADE_PATH)
    if FACE_CASCADE.empty():
        FACE_CASCADE = None
        # print("DEBUG: Failed to load Haar Cascade.")
    else:
        haar_cascade_loaded = True
        # print("DEBUG: Haar Cascade loaded successfully.")

# --- API Keys and Model IDs ---
GEMINI_API_KEY = st.secrets.get("GEMINI_API_KEY")
ROBOFLOW_API_KEY = st.secrets.get("ROBOFLOW_API_KEY")
ROBOFLOW_MODEL_ID = st.secrets.get("ROBOFLOW_MODEL_ID")
ROBOFLOW_API_URL = st.secrets.get("ROBOFLOW_API_URL", "https://detect.roboflow.com")
# print(f"DEBUG: ROBOFLOW_API_KEY: {'Set' if ROBOFLOW_API_KEY else 'Not Set'}")
# print(f"DEBUG: ROBOFLOW_MODEL_ID: {ROBOFLOW_MODEL_ID}")
# print(f"DEBUG: ROBOFLOW_API_URL: {ROBOFLOW_API_URL}")


# --- Session State ---
if 'user_name' not in st.session_state: st.session_state.user_name = ""
if 'name_submitted' not in st.session_state: st.session_state.name_submitted = False
if 'camera_active' not in st.session_state: st.session_state.camera_active = False
if 'current_emotion_for_user' not in st.session_state: st.session_state.current_emotion_for_user = None
if 'emotion_message_for_user' not in st.session_state: st.session_state.emotion_message_for_user = ""
if 'chat_history' not in st.session_state: st.session_state.chat_history = []
if 'frame_count' not in st.session_state: st.session_state.frame_count = 0
if 'ai_conversation_starter_sent' not in st.session_state: st.session_state.ai_conversation_starter_sent = False


# --- Main App UI ---
st.markdown(f"<h1 style='text-align: center; {AMHARIC_FONT_STYLE}'>á‹¨áˆµáˆœá‰µ áˆ˜áˆ˜áˆ­áˆ˜áˆªá‹« áŠ¥áŠ“ AI Chat</h1>", unsafe_allow_html=True)

if not haar_cascade_loaded:
    st.error("á‹¨ Haar Cascade áˆ˜áˆˆá‹«áŠ• áˆ˜áŒ«áŠ• áŠ áˆá‰°á‰»áˆˆáˆá¢ áŠ¥á‰£áŠ­á‹ á‹á‹­áˆ‰ áˆ˜áŠ–áˆ©áŠ• á‹«áˆ¨áŒ‹áŒáŒ¡á¢")
    st.stop()

if not st.session_state.name_submitted:
    with st.form(key="name_form"):
        name_input = st.text_input("áŠ¥á‰£áŠ­á‹ áˆµáˆá‹áŠ• á‹«áˆµáŒˆá‰¡ / Please enter your name:", key="user_name_input_form")
        submit_button = st.form_submit_button(label="áŠ áˆµáŒˆá‰£ / Submit")
        if submit_button and name_input:
            st.session_state.user_name = name_input.strip()
            st.session_state.name_submitted = True
            st.rerun()
        elif submit_button and not name_input:
            st.warning("áŠ¥á‰£áŠ­á‹ áˆµáˆá‹áŠ• á‹«áˆµáŒˆá‰¡á¢ / Please enter your name.")
    st.stop()

gemini_model = None
roboflow_client = None

with st.sidebar:
    if st.session_state.user_name:
        st.markdown(f"<h2 style='{AMHARIC_FONT_STYLE}'>áŠ¥áŠ•áŠ³áŠ• á‹°áˆ…áŠ“ áˆ˜áŒ£áˆ…, {st.session_state.user_name}!</h2>", unsafe_allow_html=True)
    st.markdown(f"<h3 style='{AMHARIC_FONT_STYLE}'>áˆ˜á‰†áŒ£áŒ áˆªá‹«á‹á‰½</h3>", unsafe_allow_html=True)
    if st.button("ğŸ“· áŠ«áˆœáˆ« áŠ á‰¥áˆ«/áŠ áŒ¥á‹", key="toggle_camera_sidebar_btn"):
        st.session_state.camera_active = not st.session_state.camera_active
        if not st.session_state.camera_active: # If camera is turned off
            st.session_state.ai_conversation_starter_sent = False # Reset starter flag

    if GEMINI_API_KEY:
        try:
            genai.configure(api_key=GEMINI_API_KEY)
            gemini_model = genai.GenerativeModel('gemini-2.0-flash')
            st.success("Gemini API á‰°áŒ€áˆáˆ¯áˆá¢", icon="âœ¨")
        except Exception as e:
            st.error(f"Gemini API áˆ˜áŒ€áˆ˜áˆ­ áŠ áˆá‰°á‰»áˆˆáˆ: {e}")
            st.caption("á‹¨áŠ¤á’áŠ á‹­ á‰áˆáá‹áŠ• áŠ¥áŠ“ áŒáŠ•áŠ™áŠá‰µá‹áŠ• á‹«áˆ¨áŒ‹áŒáŒ¡á¢")
            # print(f"DEBUG: Gemini Init Error: {e}")
    else:
        st.warning("á‹¨ Gemini API á‰áˆá áŠ áˆá‰°áŒˆáŠ˜áˆá¢")

    if ROBOFLOW_API_KEY and ROBOFLOW_API_URL and ROBOFLOW_MODEL_ID:
        try:
            roboflow_client = InferenceHTTPClient(api_url=ROBOFLOW_API_URL, api_key=ROBOFLOW_API_KEY)
            st.success("Roboflow API á‰°áŒ€áˆáˆ¯áˆá¢", icon="ğŸ¤–")
            # print("DEBUG: Roboflow client initialized.")
        except Exception as e:
            st.error(f"Roboflow API áˆ˜áŒ€áˆ˜áˆ­ áŠ áˆá‰°á‰»áˆˆáˆ: {e}")
            # print(f"DEBUG: Roboflow Init Error: {e}")
    else:
        if not ROBOFLOW_API_KEY: st.warning("á‹¨ Roboflow API á‰áˆá áŠ áˆá‰°áŒˆáŠ˜áˆá¢")
        if not ROBOFLOW_MODEL_ID: st.warning("á‹¨ Roboflow MODEL ID áŠ áˆá‰°áŒˆáŠ˜áˆá¢")
        st.warning("á‹¨áˆµáˆœá‰µ áˆ˜áˆ˜áˆ­áˆ˜áˆªá‹« á‰  Roboflow áˆ‹á‹­áŒˆáŠ á‹­á‰½áˆ‹áˆá¢")
        # print("DEBUG: Roboflow client NOT initialized (missing key, URL, or model_id).")

def translate_emotion_am(emotion_en):
    translations = {
        "angry": "áŠ•á‹´á‰µ", "disgust": "áŠ áˆµáŒ¸á‹«áŠ", "fear": "ááˆ­áˆƒá‰µ",
        "happy": "á‹°áˆµá‰³", "sad": "áˆ€á‹˜áŠ•", "surprise": "áˆ˜áŒˆáˆ¨áˆ", "surprised": "áˆ˜áŒˆáˆ¨áˆ",
        "neutral": "áŒˆáˆˆáˆá‰°áŠ›", None: "áŠ áˆá‰³á‹ˆá‰€áˆ", "": "áŠ áˆá‰³á‹ˆá‰€áˆ", "error": "áˆµáˆ…á‰°á‰µ",
        "áˆµáˆ…á‰°á‰µ": "áˆµáˆ…á‰°á‰µ"
    }
    if emotion_en == "áˆµáˆ…á‰°á‰µ": return "áˆµáˆ…á‰°á‰µ"
    return translations.get(str(emotion_en).lower() if emotion_en else "", str(emotion_en))

main_col1, main_col2 = st.columns([2, 1.5])
with main_col1:
    if st.session_state.user_name:
        st.markdown(f"<h3 style='text-align: center; {AMHARIC_FONT_STYLE}'>á‹¨áŠ«áˆœáˆ« áŠ¥á‹­á‰³ áˆˆ {st.session_state.user_name}</h3>", unsafe_allow_html=True)
    video_placeholder = st.empty()

with main_col2:
    if st.session_state.user_name:
        st.markdown(f"<h3 style='{AMHARIC_FONT_STYLE}'>á‹¨áŠ áˆáŠ‘ áˆáŠ”á‰³ áˆˆ {st.session_state.user_name}</h3>", unsafe_allow_html=True)
    emotion_text_placeholder = st.empty()
    emotion_message_placeholder = st.empty()
    st.markdown("---")
    st.markdown(f"<h3 style='{AMHARIC_FONT_STYLE}'>AI Chat (á‰ áŠ áˆ›áˆ­áŠ›)</h3>", unsafe_allow_html=True)
    
    if gemini_model:
        # Check if AI should initiate conversation based on emotion
        user_current_emotion_str = str(st.session_state.current_emotion_for_user).lower()
        if user_current_emotion_str == 'sad' and not st.session_state.ai_conversation_starter_sent and st.session_state.camera_active:
            try:
                with st.spinner("AI áˆáˆ‹áˆ½ áŠ¥á‹¨áˆ°áŒ  áŠá‹..."):
                    # AI initiates the conversation because user is sad
                    initial_ai_prompt = (
                        f"áˆ°áˆ‹áˆ {st.session_state.user_name}á¢ áŠ¥áŠ•á‹³á‹˜áŠ•áŠ­ áŠ áˆµá‰°á‹á‹«áˆˆáˆá¢ "
                        "áˆµáˆˆ áŒ‰á‹³á‹© áˆ›á‹áˆ«á‰µ á‰µáˆáˆáŒ‹áˆˆáˆ…? áˆáŠ• áŠ¥áŠ•á‹°áˆšá‹«áˆµáŒ¨áŠ•á‰…áˆ… áŠ•áŒˆáˆ¨áŠá£ áˆáŠ“áˆá‰£á‰µ áˆ‹áŒá‹áˆ… áŠ¥á‰½áˆ‹áˆˆáˆá¢"
                        "á‰ áŠ áˆ›áˆ­áŠ› á‰¥á‰» áˆ˜áˆáˆµá¢"
                    )
                    # We are not sending this as a user message, but as a direct AI utterance.
                    # For a more natural flow, we could have the AI "ask" this.
                    # Here, we'll just make it the first message from AI.

                    # For Gemini, we typically send a user prompt to get a response.
                    # To make the AI "speak first", we can construct a short history.
                    contextual_prompt_for_ai_starter = [
                        {"role": "user", "content": f"áˆ°áˆ‹áˆ AIá£ áˆµáˆœ {st.session_state.user_name} áŠá‹á¢ á‰µáŠ•áˆ½ áŠ á‹áŠ›áˆˆáˆá¢"}, # Implied user turn
                        {"role": "model", "content": initial_ai_prompt} # This is what we want the model to say as a starter
                    ]
                    # For an actual call, we'd normally send just the user part.
                    # For this "AI starter", we're simulating the AI's response to an implied situation.
                    # Let's simplify: send a prompt to Gemini AS a system instruction to generate this starter.
                    
                    # Simpler approach: AI generates a response to the *situation*
                    prompt_to_generate_starter = (
                        f"áŠ áŠ•á‰° á‰ áŒ£áˆ áŠ á‹›áŠáŠ“ á‰ áŠ áˆ›áˆ­áŠ› á‹¨áˆá‰µáŠ“áŒˆáˆ­ AI áŠáˆ…á¢ "
                        f"áˆµáˆ™ {st.session_state.user_name} á‹¨áˆ†áŠ á‰°áŒ á‰ƒáˆš áŠ¥áŠ•á‹³á‹˜áŠ áŠ áˆµá‰°á‹áˆˆáˆƒáˆá¢ "
                        f"á‹á‹­á‹­á‰±áŠ• áˆˆáˆ˜áŒ€áˆ˜áˆ­áŠ“ á‹µáŒ‹á áˆˆáˆ˜áˆµáŒ á‰µ áˆáŠ• á‰µáˆ‹áˆˆáˆ…? áˆˆáˆáˆ³áˆŒá£ 'áˆ°áˆ‹áˆ {st.session_state.user_name}á£ áŠ¥áŠ•á‹³á‹˜áŠ•áŠ­ áŠ áˆµá‰°á‹á‹«áˆˆáˆá¢ áˆµáˆˆ áŒ‰á‹³á‹© áˆ›á‹áˆ«á‰µ á‰µáˆáˆáŒ‹áˆˆáˆ…?' áˆá‰µáˆ á‰µá‰½áˆ‹áˆˆáˆ…á¢ "
                        "á‰ áŠ áˆ›áˆ­áŠ› á‰¥á‰» áˆ˜áˆáˆµá¢"
                    )
                    response = gemini_model.generate_content(prompt_to_generate_starter)
                    ai_starter_message = response.text
                    
                    if ai_starter_message:
                        st.session_state.chat_history.append({"role": "ai", "text": ai_starter_message})
                        st.session_state.ai_conversation_starter_sent = True # Prevent re-sending
                        st.rerun() # Update chat display
            except Exception as e:
                st.error(f"AI á‹á‹­á‹­á‰µ áˆ›áˆµáŒ€áˆ˜áˆªá‹« áˆ‹á‹­ áˆµáˆ…á‰°á‰µ: {e}")
                # print(f"DEBUG: AI starter error: {e}")

        chat_container = st.container()
        with chat_container:
            for entry in st.session_state.chat_history:
                role_display = "áŠ¥áˆ­áˆµá‹" if entry["role"] == "user" else "AI"
                st.markdown(f"<p style='{AMHARIC_FONT_STYLE}'><b>{role_display}:</b> {entry['text']}</p>", unsafe_allow_html=True)
        
        user_input_chat = st.text_input("áˆ˜áˆáŠ¥áŠ­á‰µá‹áŠ• á‰ áŠ áˆ›áˆ­áŠ› á‹«áˆµáŒˆá‰¡:", key="chat_input_main_form") # Changed from "áŒ¥á‹«á‰„á‹áŠ•" to "áˆ˜áˆáŠ¥áŠ­á‰µá‹áŠ•"
        if st.button("áˆ‹áŠ­", key="send_chat_main_button"):
            if user_input_chat:
                st.session_state.chat_history.append({"role": "user", "text": user_input_chat})
                
                # Construct prompt for Gemini, including context if available
                full_prompt_to_gemini = f"á‰°áŒ á‰ƒáˆšá‹ {st.session_state.user_name} áŠ¥áŠ•á‹²áˆ… á‹­áˆ‹áˆ: '{user_input_chat}'. "
                if st.session_state.current_emotion_for_user and st.session_state.current_emotion_for_user != "error":
                    user_emotion_am = translate_emotion_am(st.session_state.current_emotion_for_user)
                    if user_emotion_am != "áŠ áˆá‰³á‹ˆá‰€áˆ":
                         full_prompt_to_gemini = (
                            f"áŠ áŠ•á‰° á‰ áŒ£áˆ áŠ á‹›áŠáŠ“ á‰ áŠ áˆ›áˆ­áŠ› á‹¨áˆá‰µáŠ“áŒˆáˆ­ AI áŠáˆ…á¢ "
                            f"áˆµáˆ™ {st.session_state.user_name} á‹¨áˆ†áŠ á‰°áŒ á‰ƒáˆš áŠ áˆáŠ• {user_emotion_am} áˆµáˆœá‰µ áˆ‹á‹­ áŠ¥áŠ•á‹³áˆˆ á‰³á‹á‰ƒáˆˆáˆ…á¢ "
                            f"á‰°áŒ á‰ƒáˆšá‹ áŠ¥áŠ•á‹²áˆ… á‹­áˆ‹áˆ: '{user_input_chat}'. "
                            f"áˆˆá‹šáˆ… áˆ˜áˆáŠ¥áŠ­á‰µ áˆµáˆœá‰±áŠ• áŠ¨áŒáˆá‰µ á‹áˆµáŒ¥ á‰ áˆ›áˆµáŒˆá‰£á‰µ á‰ áŠ áˆ›áˆ­áŠ› á‰¥á‰» áˆ˜áˆáˆµá¢"
                        )
                else: # Generic prompt if no specific emotion
                    full_prompt_to_gemini = (
                        f"áŠ áŠ•á‰° á‰ áŠ áˆ›áˆ­áŠ› á‹¨áˆá‰µáŠ“áŒˆáˆ­ AI áŠáˆ…á¢ "
                        f"á‰°áŒ á‰ƒáˆšá‹ {st.session_state.user_name} áŠ¥áŠ•á‹²áˆ… á‹­áˆ‹áˆ: '{user_input_chat}'. "
                        f"á‰ áŠ áˆ›áˆ­áŠ› á‰¥á‰» áˆ˜áˆáˆµá¢"
                    )

                try:
                    with st.spinner("AI áˆáˆ‹áˆ½ áŠ¥á‹¨áˆ°áŒ  áŠá‹..."):
                        response = gemini_model.generate_content(full_prompt_to_gemini)
                        ai_response = response.text
                    st.session_state.chat_history.append({"role": "ai", "text": ai_response})
                    st.session_state.ai_conversation_starter_sent = True # Assume any user interaction means starter is handled
                    st.rerun()
                except Exception as e: 
                    st.error(f"áŠ¨ Gemini AI áŒ‹áˆ­ áˆ˜áŒˆáŠ“áŠ˜á‰µ áŠ áˆá‰°á‰»áˆˆáˆ: {e}")
                    # print(f"DEBUG: Gemini Chat Error: {e}")
            else: st.warning("áŠ¥á‰£áŠ­á‹ áˆ˜áˆáŠ¥áŠ­á‰µ á‹«áˆµáŒˆá‰¡á¢") # Changed from "áŒ¥á‹«á‰„"
    else:
        st.warning("á‹¨ Gemini API á‰áˆá áŠ áˆá‰°á‹‹á‰€áˆ¨áˆá¢")

if st.session_state.camera_active and st.session_state.name_submitted and FACE_CASCADE is not None:
    cap = cv2.VideoCapture(0)
    if not cap.isOpened():
        st.error("áŠ«áˆœáˆ«á‹áŠ• áˆ˜áŠ­áˆá‰µ áŠ áˆá‰°á‰»áˆˆáˆá¢")
        st.session_state.camera_active = False
    else:
        # print("DEBUG: Camera opened successfully.")
        while st.session_state.camera_active:
            ret, frame = cap.read()
            if not ret:
                video_placeholder.error("áŠ¨áŠ«áˆœáˆ« ááˆ¬áˆ áˆ›áŠ•á‰ á‰¥ áŠ áˆá‰°á‰»áˆˆáˆá¢"); break
            frame = cv2.flip(frame, 1)
            rgb_frame_display = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            gray_for_haar = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
            faces = FACE_CASCADE.detectMultiScale(gray_for_haar, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))

            current_emotion_val = st.session_state.current_emotion_for_user
            current_emotion_msg_val = st.session_state.emotion_message_for_user
            run_emotion_detection = (st.session_state.frame_count % 20 == 0)

            if faces is not None and len(faces) > 0:
                x, y, w, h = faces[0]
                cv2.rectangle(rgb_frame_display, (x, y), (x + w, y + h), (255, 0, 0), 2)

                if run_emotion_detection:
                    # print(f"DEBUG: Frame {st.session_state.frame_count}, attempting emotion detection.")
                    if roboflow_client and ROBOFLOW_MODEL_ID:
                        detected_emotion_api = None
                        try:
                            face_roi_bgr = frame[y:y+h, x:x+w]
                            if face_roi_bgr.size > 0:
                                is_success, im_buf_arr = cv2.imencode(".jpg", face_roi_bgr)
                                if is_success:
                                    byte_im = im_buf_arr.tobytes()
                                    # print("DEBUG: Sending image to Roboflow...")
                                    result = roboflow_client.infer(byte_im, model_id=ROBOFLOW_MODEL_ID, confidence=0.4)
                                    # print(f"DEBUG: Roboflow raw result: {result}")

                                    if result and 'predictions' in result and result['predictions']:
                                        sorted_predictions = sorted(result['predictions'], key=lambda p: p.get('confidence', 0), reverse=True)
                                        if sorted_predictions:
                                            detected_emotion_api = sorted_predictions[0].get('class')
                                            # print(f"DEBUG: Detected emotion (obj detect): {detected_emotion_api} conf {sorted_predictions[0].get('confidence')}")
                                    elif result and 'class' in result:
                                        detected_emotion_api = result.get('class')
                                        # print(f"DEBUG: Detected emotion (class): {detected_emotion_api}")
                                    elif result and 'top' in result :
                                        detected_emotion_api = result.get('top')
                                        # print(f"DEBUG: Detected emotion (top): {detected_emotion_api}")
                                    else: # No valid prediction found in result
                                        detected_emotion_api = None 
                                        # print("DEBUG: Roboflow result structure not recognized or no valid predictions.")
                                else: # imencode failed
                                    detected_emotion_api = "error" 
                                    # print("DEBUG: Failed to encode face ROI to JPG.")
                            else: # ROI empty
                                detected_emotion_api = None 
                                # print("DEBUG: Face ROI is empty.")
                            
                            st.session_state.current_emotion_for_user = detected_emotion_api
                            if detected_emotion_api and str(detected_emotion_api).lower() == 'sad':
                                st.session_state.emotion_message_for_user = "áˆˆáˆáŠ• áŠ á‹˜áŠ•áŠ­?"
                                # If AI hasn't started convo about sadness and camera is on, it might do so on next UI update
                                # Resetting here allows it to trigger if sadness persists
                                if not st.session_state.ai_conversation_starter_sent:
                                     pass # Let the AI chat section handle it
                            else:
                                st.session_state.emotion_message_for_user = ""
                            
                            current_emotion_val = st.session_state.current_emotion_for_user
                            current_emotion_msg_val = st.session_state.emotion_message_for_user

                        except Exception as e:
                            # print(f"DEBUG: Roboflow emotion detection EXCEPTION: {e}")
                            st.session_state.current_emotion_for_user = "áˆµáˆ…á‰°á‰µ"
                            st.session_state.emotion_message_for_user = ""
                            current_emotion_val = "áˆµáˆ…á‰°á‰µ"
                            current_emotion_msg_val = ""
                    # else: print("DEBUG: Roboflow client or model ID not available for emotion detection.")
            else: # No faces
                if run_emotion_detection:
                    # print("DEBUG: No faces detected, clearing emotion.")
                    st.session_state.current_emotion_for_user = None
                    st.session_state.emotion_message_for_user = ""
                    current_emotion_val = None
                    current_emotion_msg_val = ""

            video_placeholder.image(rgb_frame_display, channels="RGB", use_container_width=True)
            
            if st.session_state.user_name:
                emotion_display_text = translate_emotion_am(current_emotion_val)
                emotion_text_placeholder.markdown(f"<p style='{AMHARIC_FONT_STYLE}'><b>á‹¨ {st.session_state.user_name} áˆµáˆœá‰µ:</b> {emotion_display_text}</p>", unsafe_allow_html=True)
                if current_emotion_msg_val: # Only show if there's a specific message
                    emotion_message_placeholder.markdown(f"<p style='color:red; {AMHARIC_FONT_STYLE}'>{current_emotion_msg_val}</p>", unsafe_allow_html=True)
                else: # Clear if no specific message (e.g. user is not sad)
                    emotion_message_placeholder.empty()


            st.session_state.frame_count +=1
            time.sleep(0.05) 

        cap.release()
        # print("DEBUG: Camera released.")
        if not st.session_state.camera_active:
             video_placeholder.empty()
             emotion_text_placeholder.empty()
             emotion_message_placeholder.empty()
else:
    if st.session_state.name_submitted and FACE_CASCADE is not None:
        video_placeholder.info(f"{st.session_state.user_name}á£ á‹¨á‰€áŒ¥á‰³ á‹¨áŠ«áˆœáˆ« áŠ¥á‹­á‰³áŠ• áˆˆáˆ›áˆ³á‹¨á‰µ 'áŠ«áˆœáˆ« áŠ á‰¥áˆ«/áŠ áŒ¥á‹' á‹¨áˆšáˆˆá‹áŠ• á‹­áŒ«áŠ‘á¢")
    elif not st.session_state.name_submitted:
        pass 
    elif FACE_CASCADE is None:
        video_placeholder.error("á‹¨áŠá‰µ áˆ˜áˆˆá‹« áˆáŒáˆ áˆ˜áŒ«áŠ• áŠ áˆá‰°á‰»áˆˆáˆá¢ áŠ«áˆœáˆ« áŠ á‹­áŒˆáŠáˆá¢")
        
    if st.session_state.name_submitted :
        emotion_text_placeholder.empty()
        emotion_message_placeholder.empty()